{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\faizan\\\\Documents\\\\IMLChallenge02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "sample_df = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_missing_values = train_df.isnull().sum()\n",
    "train_data_types = train_df.dtypes\n",
    "\n",
    "test_missing_values = test_df.isnull().sum()\n",
    "test_data_types = test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "X_train = train_df.drop(['price_doc'], axis=1)\n",
    "y_train = train_df['price_doc']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values for numerical features with median\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "X_train[num_cols] = imputer_num.fit_transform(X_train[num_cols])\n",
    "test_df[num_cols] = imputer_num.transform(test_df[num_cols])\n",
    "\n",
    "# Impute missing values for categorical features with mode\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "X_train[cat_cols] = imputer_cat.fit_transform(X_train[cat_cols])\n",
    "test_df[cat_cols] = imputer_cat.transform(test_df[cat_cols])\n",
    "\n",
    "# Check if there are any missing values left\n",
    "X_train.isnull().sum().sum(), test_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the numerical columns using StandardScaler\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for categorical features\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=cat_cols)\n",
    "test_df_encoded = pd.get_dummies(test_df, columns=cat_cols)\n",
    "\n",
    "# Ensure that both training and test data have the same set of columns after one-hot encoding\n",
    "missing_cols = set(X_train_encoded.columns) - set(test_df_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    test_df_encoded[col] = 0\n",
    "\n",
    "test_df_encoded = test_df_encoded[X_train_encoded.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 2214)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply label encoding to categorical columns in both train and test data\n",
    "for col in cat_cols:\n",
    "    X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    test_df[col] = label_encoder.transform(test_df[col])\n",
    "\n",
    "\n",
    "# Ensure that both training and test data have the same set of columns after one-hot encoding\n",
    "missing_cols = set(X_train_encoded.columns) - set(test_df_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    test_df_encoded[col] = 0\n",
    "\n",
    "test_df_encoded = test_df_encoded[X_train_encoded.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 2214)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.99 GiB for an array with shape (2214, 181507) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\faizan\\Documents\\IMLChallenge02\\Regression.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/faizan/Documents/IMLChallenge02/Regression.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Model Training\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/faizan/Documents/IMLChallenge02/Regression.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/faizan/Documents/IMLChallenge02/Regression.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_encoded, y_train)\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[39m=\u001b[39m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1149\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1150\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1151\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1152\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1153\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1154\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1155\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1156\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1157\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1158\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:2083\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2083\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values\n\u001b[0;32m   2084\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(values, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m   2085\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2086\u001b[0m         astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m   2087\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2088\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mis_single_block\n\u001b[0;32m   2089\u001b[0m     ):\n\u001b[0;32m   2090\u001b[0m         \u001b[39m# Check if both conversions can be done without a copy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:1049\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1047\u001b[0m blocks \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mblocks\n\u001b[0;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(blocks) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1049\u001b[0m     \u001b[39mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m   1051\u001b[0m arr \u001b[39m=\u001b[39m blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[39m# non-2D ExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:12284\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12210\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m  12211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalues\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m  12212\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  12213\u001b[0m \u001b[39m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12214\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12282\u001b[0m \u001b[39m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12283\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12284\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1657\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\faizan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1689\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[39m# error: Argument 1 to \"ensure_np_dtype\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[39m# \"Optional[dtype[Any]]\"; expected \"Union[dtype[Any], ExtensionDtype]\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m dtype \u001b[39m=\u001b[39m ensure_np_dtype(dtype)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 1689\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m   1691\u001b[0m itemmask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1693\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m   1694\u001b[0m     \u001b[39m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.99 GiB for an array with shape (2214, 181507) and data type float64"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize Recursive Feature Elimination with Cross-Validation (RFECV)\n",
    "selector = RFECV(estimator=model, step=1, cv=5)\n",
    "\n",
    "# Fit RFECV on your data\n",
    "selector = selector.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Transform your data to include only the selected features\n",
    "X_train_selected = selector.transform(X_train_encoded)\n",
    "X_test_selected = selector.transform(X_test_encoded)\n",
    "\n",
    "# Train your model on the selected features\n",
    "model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained model on the test data\n",
    "X_test_encoded = pd.get_dummies(test_df, columns=cat_cols)  # One-hot encode the test data\n",
    "missing_cols_test = set(X_train_encoded.columns) - set(X_test_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the test data has the same columns as the training data after one-hot encoding\n",
    "for col in missing_cols_test:\n",
    "    X_test_encoded[col] = 0\n",
    "\n",
    "X_test_encoded = X_test_encoded[X_train_encoded.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical columns using StandardScaler\n",
    "X_test_encoded[num_cols] = scaler.transform(X_test_encoded[num_cols])\n",
    "\n",
    "# Make predictions\n",
    "predicted_price = model.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'row ID': test_df['row ID'],\n",
    "    'price_doc': predicted_price\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('prediction_linearRegression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "del test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
